[
  {
    "path": "posts/introduction/",
    "title": "0 - A Look at the Toolbox",
    "description": "Some background on methods and possibilities of digital text analysis, specifically in studying plays.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-10-20",
    "categories": [],
    "contents": "\n\nContents\nWhat is digital text analysis?Sentiment analysis“Positive” versus “negative” words\nTag for more than 2 emotions\n\nTag for parts of speech\nTag for semantic classes\n\nStart by loading our data\nNarrowing down our interest\nTag for sentiment\n\n\n\n\n\n\n\nWhat is digital text analysis?\nHaving read the NYT piece about social media text analysis, and perhaps from your own life in this digital world of ours!!, you have at least heard about some of the methods that a “computational sociolinguist” or a “digital humanist” might apply to text.\nSentiment analysis\n“Positive” versus “negative” words\nSentiment analysis: n pos v. n neg per text.Sentiment analysis: comparing pos:neg ratios.Sentiment analysis: split each text into 100 slices, then track sentiment curve.Sentiment analysis: same as above, but with act boundaries marked.Tag for more than 2 emotions\nSentiment analysis: pos, neg, and 8 other sentiment categories.Tag for parts of speech\n\nknitr::include_graphics(\"pos_tagset.png\", dpi=100)\n\n\nTag for semantic classes\n\nknitr::include_graphics(\"semantic_tagset.png\", dpi=100)\n\n\nStart by loading our data\nFirst we’ll get an inventory of all the .DOCX files in our project directory.\n\n(textfiles <- list.files(pattern = \".docx\"))\n[1] \"prose and verse csv 500 words.docx\"\n[2] \"Prose and Verse from Shrew.docx\"   \n\nThe second file has more formatting and may, for the time being, be more useful. We’ll read it in. Here is the top of its content.\n\nf <- read_docx(textfiles[2])\nf %>% head(10)\n [1] \"I am  Christophero  Sly; call not me ' honour ' nor 'lordship.' I\"\n [2] \"ne'er drank sack in my life; and if you give me any conserves,\"   \n [3] \"give me conserves of beef. Ne'er ask me what raiment I'll wear,\"  \n [4] \"for I have no more doublets than backs, no more stockings than\"   \n [5] \"legs, nor no more shoes than feet- nay, sometime more feet than\"  \n [6] \"shoes, or such shoes as my toes look through the  overleather .\"  \n [7] \"Lord. Heaven cease this idle  humour  in your  honour !\"          \n [8] \"What, would you make me mad? Am not I Christopher Sly, old\"       \n [9] \"Sly's  son of Burton Heath; by birth a  pedlar , by education a\"  \n[10] \"cardmaker , by transmutation a bear-herd, and now by present\"     \n\nHere it is, converted to tabular format.\n\n\nf <- \n  f %>% \n  enframe() %>% \n  select(line = 2) %>% \n  mutate(file = textfiles[2])\nf %>% \n  head(10) %>% \n  kbl() %>% \n  kable_styling(bootstrap_options = \"striped\", \n                full_width = F, \n                position = \"left\") \n\nline\n\n\nfile\n\n\nI am Christophero Sly; call not me ’ honour ’ nor ‘lordship.’ I\n\n\nProse and Verse from Shrew.docx\n\n\nne’er drank sack in my life; and if you give me any conserves,\n\n\nProse and Verse from Shrew.docx\n\n\ngive me conserves of beef. Ne’er ask me what raiment I’ll wear,\n\n\nProse and Verse from Shrew.docx\n\n\nfor I have no more doublets than backs, no more stockings than\n\n\nProse and Verse from Shrew.docx\n\n\nlegs, nor no more shoes than feet- nay, sometime more feet than\n\n\nProse and Verse from Shrew.docx\n\n\nshoes, or such shoes as my toes look through the overleather .\n\n\nProse and Verse from Shrew.docx\n\n\nLord. Heaven cease this idle humour in your honour !\n\n\nProse and Verse from Shrew.docx\n\n\nWhat, would you make me mad? Am not I Christopher Sly, old\n\n\nProse and Verse from Shrew.docx\n\n\nSly’s son of Burton Heath; by birth a pedlar , by education a\n\n\nProse and Verse from Shrew.docx\n\n\ncardmaker , by transmutation a bear-herd, and now by present\n\n\nProse and Verse from Shrew.docx\n\n\nNarrowing down our interest\nI have just received the latest notes from class: the interest seems to be in the difference between verse and prose crossed with an interest in character. I interpret this to mean that there are characters that appear both in verse and in prose sections, and we want to know how the language associated with each character differs from verse to prose.\nIn the text samples I have, character speech is not marked. We might be better off if we pull Taming of the Shrew from www.gutenberg.org.\nLuckily there is an R module that interfaces with the Gutenberg archives. It is called gutenbergr. I will pull the whole text from there.\n\n\nshakespeare <- \n  gutenberg_works(author == \"Shakespeare, William\") \n\nshakespeare                    %>% \n  mutate(entry = row_number()) %>% \n  select(entry, title)  %>% \n  kbl() %>% \n  kable_styling(bootstrap_options = \"striped\", \n                full_width = F, \n                position = \"left\") \n\nentry\n\n\ntitle\n\n\n1\n\n\nShakespeare’s Sonnets\n\n\n2\n\n\nVenus and Adonis\n\n\n3\n\n\nKing Henry VI, First Part\n\n\n4\n\n\nHistory of King Henry the Sixth, Second Part\n\n\n5\n\n\nThe History of King Henry the Sixth, Third Part\n\n\n6\n\n\nThe Tragedy of King Richard III\n\n\n7\n\n\nThe Comedy of Errors\n\n\n8\n\n\nThe Rape of Lucrece\n\n\n9\n\n\nThe Tragedy of Titus Andronicus\n\n\n10\n\n\nThe Taming of the Shrew\n\n\n11\n\n\nThe Two Gentlemen of Verona\n\n\n12\n\n\nLove’s Labour’s Lost\n\n\n13\n\n\nKing John\n\n\n14\n\n\nThe Tragedy of King Richard the Second\n\n\n15\n\n\nRomeo and Juliet\n\n\n16\n\n\nA Midsummer Night’s Dream\n\n\n17\n\n\nThe Merchant of Venice\n\n\n18\n\n\nKing Henry IV, the First Part\n\n\n19\n\n\nThe Merry Wives of Windsor\n\n\n20\n\n\nKing Henry IV, Second Part\n\n\n21\n\n\nMuch Ado about Nothing\n\n\n22\n\n\nThe Life of King Henry V\n\n\n23\n\n\nJulius Caesar\n\n\n24\n\n\nAs You Like It\n\n\n25\n\n\nHamlet, Prince of Denmark\n\n\n26\n\n\nThe Phoenix and the Turtle\n\n\n27\n\n\nTwelfth Night; Or, What You Will\n\n\n28\n\n\nThe History of Troilus and Cressida\n\n\n29\n\n\nAll’s Well That Ends Well\n\n\n30\n\n\nMeasure for Measure\n\n\n31\n\n\nOthello, the Moor of Venice\n\n\n32\n\n\nThe Tragedy of King Lear\n\n\n33\n\n\nMacbeth\n\n\n34\n\n\nAntony and Cleopatra\n\n\n35\n\n\nThe Tragedy of Coriolanus\n\n\n36\n\n\nThe Life of Timon of Athens\n\n\n37\n\n\nPericles, Prince of Tyre\n\n\n38\n\n\nCymbeline\n\n\n39\n\n\nThe Winter’s Tale\n\n\n40\n\n\nThe Tempest\n\n\n41\n\n\nThe Life of Henry the Eighth\n\n\n42\n\n\nA Lover’s Complaint\n\n\n43\n\n\nThe Passionate Pilgrim\n\n\n44\n\n\nTwelfth Night\n\n\n45\n\n\nRichard II\n\n\n46\n\n\nHenry IV, Part 1\n\n\n47\n\n\nHenry V\n\n\n48\n\n\nHenry VI, Part 1\n\n\n49\n\n\nHenry VI, Part 2\n\n\n50\n\n\nHenry VI, Part 3\n\n\n51\n\n\nRichard III\n\n\n52\n\n\nHenry VIII\n\n\n53\n\n\nCoriolanus\n\n\n54\n\n\nTitus Andronicus\n\n\n55\n\n\nTimon of Athens\n\n\n56\n\n\nHamlet\n\n\n57\n\n\nKing Lear\n\n\n58\n\n\nOthello\n\n\n59\n\n\nShakespeare’s First Folio\n\n\n60\n\n\nThe Tragicall Historie of Hamlet, Prince of Denmarke The First (‘Bad’) Quarto\n\n\n61\n\n\nThe Tragedie of Hamlet, Prince of Denmark A Study with the Text of the Folio of 1623\n\n\n62\n\n\nShakespeare’s play of the Merchant of Venice Arranged for Representation at the Princess’s Theatre, with Historical and Explanatory Notes by Charles Kean, F.S.A.\n\n\n63\n\n\nKing Henry the Fifth Arranged for Representation at the Princess’s Theatre\n\n\n64\n\n\nThe Works of William Shakespeare [Cambridge Edition] [9 vols.] Introduction and Publisher’s Advertising\n\n\n65\n\n\nThe Tempest The Works of William Shakespeare [Cambridge Edition] [9 vols.]\n\n\n66\n\n\nTwo Gentlemen of Verona The Works of William Shakespeare [Cambridge Edition] [9 vols.]\n\n\n67\n\n\nThe Merry Wives of Windsor The Works of William Shakespeare [Cambridge Edition] [9 vols.]\n\n\n68\n\n\nMeasure for Measure The Works of William Shakespeare [Cambridge Edition] [9 vols.]\n\n\n69\n\n\nThe Comedy of Errors The Works of William Shakespeare [Cambridge Edition] [9 vols.]\n\n\n70\n\n\nThe New Hudson Shakespeare: Julius Cæsar\n\n\n71\n\n\nThe Works of William Shakespeare [Cambridge Edition] [Vol. 2]\n\n\n72\n\n\nShakespeare’s Comedy of The Tempest\n\n\n73\n\n\nThe Works of William Shakespeare [Cambridge Edition] [Vol. 7 of 9]\n\n\n74\n\n\nShakespeare’s Tragedy of Romeo and Juliet\n\n\n75\n\n\nThe Works of William Shakespeare [Cambridge Edition] [Vol. 6 of 9 vols.]\n\n\n76\n\n\nThe Works of William Shakespeare [Cambridge Edition] [Vol. 8 of 9 vols.]\n\n\n77\n\n\nThe Works of William Shakespeare [Cambridge Edition] [Vol. 5 of 9] I, II, and III King Henry Sixth; King Richard III; and two other related plays.\n\n\n78\n\n\nThe Works of William Shakespeare - Cambridge Edition (4 of 9) (1863)\n\n\n79\n\n\nThe Works of William Shakespeare - Cambridge Edition (3 of 9) (1863)\n\n\nSo our text is there and available, at index no. 10.\n\nIDs <-  shakespeare[c(10),]$gutenberg_id\n\nshakespeare %>% \n  filter(gutenberg_id %in% IDs) %>% \n  select(gutenberg_id, title)\n# A tibble: 1 x 2\n  gutenberg_id title                  \n         <int> <chr>                  \n1         1508 The Taming of the Shrew\n\nLet’s download the play and store it in an R object. I will call it plays (plural in case we add more texts or something.)\n\nplays <- gutenberg_download(IDs, meta_fields = \"title\")\n\nplays %>% as_tibble()\n# A tibble: 4,829 x 3\n   gutenberg_id text                       title                  \n          <int> <chr>                      <chr>                  \n 1         1508 \"THE TAMING OF THE SHREW\"  The Taming of the Shrew\n 2         1508 \"\"                         The Taming of the Shrew\n 3         1508 \"by William Shakespeare\"   The Taming of the Shrew\n 4         1508 \"\"                         The Taming of the Shrew\n 5         1508 \"\"                         The Taming of the Shrew\n 6         1508 \"\"                         The Taming of the Shrew\n 7         1508 \"\"                         The Taming of the Shrew\n 8         1508 \"Dramatis Personae\"        The Taming of the Shrew\n 9         1508 \"\"                         The Taming of the Shrew\n10         1508 \"Persons in the Induction\" The Taming of the Shrew\n# … with 4,819 more rows\n\nI’ll convert the data to one-word-per row now. It’s the format we need for any of these analyses.\n\n\nsentiments <- plays %>%\n  #group_by(title) %>%\n  mutate(line = row_number()) %>% \n  unnest_tokens(word, text,\n                to_lower = F) \n\nsentiments %>% \n  slice(150:190) %>% \n  kbl() %>% \n  kable_styling(bootstrap_options = \"striped\", \n                full_width = F, \n                position = \"left\") \n\ngutenberg_id\n\n\ntitle\n\n\nline\n\n\nword\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n68\n\n\nTherefore\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n68\n\n\npaucas\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n69\n\n\npallabris\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n69\n\n\nlet\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n69\n\n\nthe\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n69\n\n\nworld\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n69\n\n\nslide\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n69\n\n\nSessa\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n71\n\n\nHOSTESS\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nYou\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nwill\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nnot\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\npay\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nfor\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nthe\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nglasses\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nyou\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nhave\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n72\n\n\nburst\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n74\n\n\nSLY\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nNo\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nnot\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\na\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\ndenier\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nGo\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nby\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nSaint\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nJeronimy\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\ngo\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nto\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nthy\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\ncold\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n75\n\n\nbed\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n76\n\n\nand\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n76\n\n\nwarm\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n76\n\n\nthee\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n78\n\n\nHOSTESS\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n79\n\n\nI\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n79\n\n\nknow\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n79\n\n\nmy\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n79\n\n\nremedy\n\n\nWith my well-trained eye, I notice that “character names designating who’s speaking” are all set in all-caps. Given this material property, we can insert a column into the data that states, for each word, who is speaking it.\n\nA much nicer technical term is speech prefix.\n\nplay_with_speaker <- \n  sentiments %>% \n  mutate(speaker = NA)\n\ntwo_word_name <- FALSE\n\nspeakername <- NA\n\nfor (i in (1:nrow(play_with_speaker))){\n  \n  # define the word that this loop looks at\n  myword = play_with_speaker[i,] %>% \n    pull(word)\n  \n  # check whether word is identitcal to its all-caps conversion\n  # if yes, then set it as speaker name\n  if (myword == toupper(myword) & nchar(myword) > 1){\n    speakername = myword\n  }\n  \n  # write speaker name in speaker column\n  play_with_speaker$speaker[i] = speakername\n  cat(\"\\014\", i, \"of\", nrow(play_with_speaker))\n}\ncat(\"\\014\")\n\nWe’ll export the dataset we’ve created so that next time the chunk won’t need to run. We’ll only need to import the data then.\n\nplay_with_speaker %>% \n  export(\"play_with_speaker.csv\")\n\n\nplay_with_speaker <- \n  import(\"play_with_speaker.csv\")\n\nLet’s get a printout of the number of words spoken by each character.\n\n\nplay_with_speaker %>% \n  count(speaker, sort = T) %>% \n  filter(n > 25) %>% \n  kbl(caption = \"Words per character (showing only those with more than 25)\") %>% \n  kable_styling(position = \"left\",\n                bootstrap_options = \"striped\", \n                full_width = F)\n\nTable 1: Words per character (showing only those with more than 25)\n\n\nspeaker\n\n\nn\n\n\nPETRUCHIO\n\n\n4494\n\n\nTRANIO\n\n\n2423\n\n\nKATHERINA\n\n\n1900\n\n\nHORTENSIO\n\n\n1882\n\n\nLUCENTIO\n\n\n1625\n\n\nGRUMIO\n\n\n1540\n\n\nGREMIO\n\n\n1354\n\n\nBAPTISTA\n\n\n1177\n\n\nBIONDELLO\n\n\n933\n\n\nLORD\n\n\n808\n\n\nBIANCA\n\n\n677\n\n\nSERVANT\n\n\n600\n\n\nSLY\n\n\n598\n\n\nVINCENTIO\n\n\n469\n\n\nPEDANT\n\n\n453\n\n\nPLAYERS\n\n\n214\n\n\nCURTIS\n\n\n199\n\n\nTAILOR\n\n\n139\n\n\nPAGE\n\n\n136\n\n\nSERVANTS\n\n\n112\n\n\nWIDOW\n\n\n112\n\n\nHUNTSMAN\n\n\n110\n\n\nSCENE\n\n\n57\n\n\nPLAYER\n\n\n35\n\n\nHOSTESS\n\n\n34\n\n\nNATHANIEL\n\n\n26\n\n\nFor later use, let’s retain a list of the speakers who have significant enough amounts of speech. Let’s set the cutoff even a bit higher, at 400 words.\n\nsig_speakers <- \n  play_with_speaker %>% \n  count(speaker) %>% \n  arrange(desc(n)) %>% \n  filter(n >400) %>% \n  pull(speaker)\nsig_speakers\n [1] \"PETRUCHIO\" \"TRANIO\"    \"KATHERINA\" \"HORTENSIO\" \"LUCENTIO\" \n [6] \"GRUMIO\"    \"GREMIO\"    \"BAPTISTA\"  \"BIONDELLO\" \"LORD\"     \n[11] \"BIANCA\"    \"SERVANT\"   \"SLY\"       \"VINCENTIO\" \"PEDANT\"   \n\nBelow is a preview of the data format in which every row shows in the speaker column which character speaks it.\n\n\nplay_with_speaker %>% \n  slice(340:400) %>% \n  kbl() %>% \n  kable_styling(position = \"left\",\n                full_width = F)\n\ngutenberg_id\n\n\ntitle\n\n\nline\n\n\nword\n\n\nspeaker\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n108\n\n\nesteem\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n108\n\n\nhim\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n108\n\n\nworth\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n108\n\n\na\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n108\n\n\ndozen\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n108\n\n\nsuch\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nBut\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nsup\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nthem\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nwell\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nand\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nlook\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nunto\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nthem\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n109\n\n\nall\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nTo\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nmorrow\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nI\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nintend\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nto\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nhunt\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n110\n\n\nagain\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n112\n\n\nFIRST\n\n\nFIRST\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n112\n\n\nHUNTSMAN\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n113\n\n\nI\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n113\n\n\nwill\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n113\n\n\nmy\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n113\n\n\nlord\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n115\n\n\nLORD\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\nSees\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\nSly\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\nWhat’s\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\nhere\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\nOne\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\ndead\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\nor\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n116\n\n\ndrunk\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n117\n\n\nSee\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n117\n\n\ndoth\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n117\n\n\nhe\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n117\n\n\nbreathe\n\n\nLORD\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n119\n\n\nSECOND\n\n\nSECOND\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n119\n\n\nHUNTSMAN\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nHe\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nbreathes\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nmy\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nlord\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nWere\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nhe\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nnot\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nwarm’d\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nwith\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n120\n\n\nale\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\nThis\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\nwere\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\na\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\nbed\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\nbut\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\ncold\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\nto\n\n\nHUNTSMAN\n\n\n1508\n\n\nThe Taming of the Shrew\n\n\n121\n\n\nsleep\n\n\nHUNTSMAN\n\n\nTag for sentiment\nFor now, we’ll just tag for pos. and neg. sentiment words\n\n\nsentiment <- \n  play_with_speaker %>% \n  mutate(word = tolower(word)) %>% \n  anti_join(stop_words) %>%          \n  inner_join(get_sentiments(\"bing\")) %>% \n  select(speaker, word, sentiment)\n\nsentiment %>% \n  slice(300:330) %>% \n  kbl() %>% \n  kable_styling(position = \"left\",\n                full_width = F)\n\nspeaker\n\n\nword\n\n\nsentiment\n\n\nLUCENTIO\n\n\nsweet\n\n\npositive\n\n\nLUCENTIO\n\n\nbeauty\n\n\npositive\n\n\nLUCENTIO\n\n\nhumble\n\n\npositive\n\n\nTRANIO\n\n\nscold\n\n\nnegative\n\n\nTRANIO\n\n\ndin\n\n\nnegative\n\n\nLUCENTIO\n\n\nsweet\n\n\npositive\n\n\nTRANIO\n\n\nlove\n\n\npositive\n\n\nTRANIO\n\n\nmaster\n\n\npositive\n\n\nTRANIO\n\n\nlove\n\n\npositive\n\n\nLUCENTIO\n\n\ncruel\n\n\nnegative\n\n\nTRANIO\n\n\nmaster\n\n\npositive\n\n\nLUCENTIO\n\n\nmaster\n\n\npositive\n\n\nLUCENTIO\n\n\nmaster\n\n\npositive\n\n\nLUCENTIO\n\n\ncharm\n\n\npositive\n\n\nTRANIO\n\n\npleasure\n\n\npositive\n\n\nTRANIO\n\n\nlove\n\n\npositive\n\n\nLUCENTIO\n\n\nloves\n\n\npositive\n\n\nLUCENTIO\n\n\nslave\n\n\nnegative\n\n\nLUCENTIO\n\n\nrogue\n\n\nnegative\n\n\nBIONDELLO\n\n\nmaster\n\n\npositive\n\n\nLUCENTIO\n\n\nquarrel\n\n\nnegative\n\n\nLUCENTIO\n\n\nfear\n\n\nnegative\n\n\nTRANIO\n\n\nfaith\n\n\npositive\n\n\nTRANIO\n\n\nmaster\n\n\npositive\n\n\nSLY\n\n\nsly\n\n\nnegative\n\n\nSLY\n\n\nsaint\n\n\npositive\n\n\nSLY\n\n\nsly\n\n\nnegative\n\n\nSLY\n\n\nexcellent\n\n\npositive\n\n\nPETRUCHIO\n\n\nbeloved\n\n\npositive\n\n\nPETRUCHIO\n\n\nknock\n\n\nnegative\n\n\nGRUMIO\n\n\nknock\n\n\nnegative\n\n\nWith this data available, we can now plot the sentiment-per-speaker.\nFirst we’ll make a second dataset that is “wider”: it has one row per speaker and it summarizes n_neg, n_pos, n_total, and neg_ratio.\n\nsentiment_wide <- \n  sentiment %>% \n  filter(speaker %in% sig_speakers) %>% \n  count(speaker, sentiment) %>% \n  pivot_wider(\n    names_from = sentiment,\n    values_from = n\n  ) %>% \n  mutate(n_total = negative + positive,\n         neg_ratio = negative/positive) %>% \n  rename(n_neg = negative,\n         n_pos = positive)\n\nSome of this info will be useful to have in the main dataset sentiment. Therefore we’ll left_join() the two.\n\nsentiment %>% \n  filter(speaker %in% sig_speakers) %>% \n  count(speaker, sentiment) %>% \n  left_join(select(sentiment_wide, speaker, n_total)) %>% \n  #---start plot code---#\n  ggplot(aes(x = sentiment,\n             y = n/n_total,\n             fill = speaker)) +\n  scale_y_continuous(labels = scales::percent_format()) +\n  geom_bar(stat = \"identity\",\n           position = \"dodge\") +\n  scale_fill_viridis_d() +\n  facet_wrap(~speaker) + \n  labs(y=\"sentiment words scored\") +\n  theme_classic(base_family = \"Roboto Condensed\") +\n  theme(legend.position = \"none\")\n\n\nFigure 1: The ratio between neg. and pos.-coded words by character.\n\n\n\nLet’s now plot just one bar for each speaker, the neg:pos ratio (or neg_ratio, as I will call it). So the highest value will be for the character with the most negative words.\n\nsentiment_wide %>% \n  #---start plot code---#\n  ggplot(aes(x = reorder(speaker, neg_ratio),\n             y = neg_ratio,\n             fill = -(neg_ratio)\n             )) +\n   geom_hline(yintercept = 1,\n             colour=\"black\", \n             linetype=\"dashed\") +\n  geom_col(alpha=0.8) +\n  scale_fill_viridis_b() +\n  labs(\n    title=\"Sentiment ratio by character\",\n    subtitle=\"Values > 1 indicate greater negative counts\",\n    caption=\"The Taming of the Shrew\",\n    y=\"negative vs. positive words\",\n       x=NULL) +\n  coord_flip() +\n  theme_classic(base_family = \"Roboto Condensed\") +\n  theme(legend.position = \"none\")\n\n\nFigure 2: Sly must be miserable to be around.\n\n\n\n\n\n\n",
    "preview": "posts/introduction/toolbox.png",
    "last_modified": "2020-10-21T09:53:54-04:00",
    "input_file": {}
  },
  {
    "path": "posts/dataprep/",
    "title": "1 - Data Preparation",
    "description": "Preparation of the pre-cleaned and speaker/genre-tagged play text.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-10-18",
    "categories": [],
    "contents": "\n\nContents\nThe data: gold-standard preparationLoading the file into R\nCurrent size\n\nFurther processingChange genre tags to lexical tags\nEdit speech prefixes\nMark acts\nTokenize\nMark each row for current speaker\nMark each row for current genre\n\nThe final file\n\n\n\n\nThe data: gold-standard preparation\nWe have pre-cleaned the data and hand-coded it for genre. That is the gold standard. In addition, speech prefixes were retained and systematically set to all-caps. Stage directions were removed. Below is a screenshot of the current version.\n\n\n\nFigure 1: Current version of the text: pre-cleaned and hand-tagged for genre.\n\n\n\nLoading the file into R\nReading in the file, the head looks as below.\n\n\nTable 1: The text as initial R object.\n\n\nlinenumber\n\n\ntext\n\n\n65\n\n\nAnd when he says he is, say that he dreams,\n\n\n66\n\n\nFor he is nothing but a mighty lord.\n\n\n67\n\n\nThis do, and do it kindly, gentle sirs;\n\n\n68\n\n\nIt will be pastime passing excellent,\n\n\n69\n\n\nIf it be husbanded with modesty. <\/verse>\n\n\n70\n\n\n<1. HUNTSMAN> <verse>My lord, I warrant you we will play our part\n\n\n71\n\n\nAs he shall think by our true diligence\n\n\n72\n\n\nHe is no less than what we say he is. <\/verse>\n\n\n73\n\n\n<LORD> <verse>Take him up gently and to bed with him,\n\n\n74\n\n\nAnd each one to his office when he wakes.\n\n\n75\n\n\nSirrah, go see what trumpet ’tis that sounds.\n\n\nCurrent size\nThe text has been read line-by-line. The current length is 2 799 lines. As we process it, we’ll find out the number of words.\nFurther processing\nThe following things need to happen before any analysis.\nWe’ll want to convert the text to one-word-per-row format. This step typically (a) removes all punctuation and (b) changes upper-case to lower-case letters. We don’t really want either of these, but getting rid of punctution is darn useful. So we will want punctuation removed, but we need to do something to retain the valuable genre-tagging. To address a), then, I’ll change our XML format tags (e.g. <prose>...<\/prose>) to lexical tags, i.e. made-up words I can be sure Shakespeare didn’t use in the play: prosestart ... proseend, versestart ... verseend. This will allow me to still remove any punctuation while retaining the genre tagging.\n\nWhy not? Because are relying on capitalization to identify speech prefixes, and on punctuation to identify genre tagging.\nEdit those speech prefixes that, like the huntsmen, consist of more than one token.\nMark each line for current act.\nAt this point, “tokenize”, i.e. change format to one-word-per-row.\nIdentify all words in all-caps spelling – we know these are the speech prefixes. Use them to mark each row for the current speaker.\nIdentify all genre tags. Use them to mark each row for prose or verse as genre.\nI’ll now work down this list and show the state of the text after each conversion.\nChange genre tags to lexical tags\n\n\nTable 2: Data after genre tags have been changed from XML format to lexical forms.\n\n\nlinenumber\n\n\ntext\n\n\n65\n\n\nAnd when he says he is, say that he dreams,\n\n\n66\n\n\nFor he is nothing but a mighty lord.\n\n\n67\n\n\nThis do, and do it kindly, gentle sirs;\n\n\n68\n\n\nIt will be pastime passing excellent,\n\n\n69\n\n\nIf it be husbanded with modesty. verseend\n\n\n70\n\n\n<1. HUNTSMAN> versestart My lord, I warrant you we will play our part\n\n\n71\n\n\nAs he shall think by our true diligence\n\n\n72\n\n\nHe is no less than what we say he is. verseend\n\n\n73\n\n\n<LORD> versestart Take him up gently and to bed with him,\n\n\n74\n\n\nAnd each one to his office when he wakes.\n\n\n75\n\n\nSirrah, go see what trumpet ’tis that sounds.\n\n\nEdit speech prefixes\nI went back to the DOCX file to be able to read better, and tried to find any character name that consisted of more than one token. Here are the ones I came up with.\n\nDo let me know if I overlooked any. Additions can be easily made.\n<1. HUNTSMAN>: change to HUNTSMAN1\n<2. HUNTSMAN>: change to HUNTSMAN2\n<3. SERVANT>: change to SERVANT3\n<2. SERVANT>: change to SERVANT2\n<1. SERVANT>: change to SERVANT1\n\n\n\nNo need to display the result here.\nMark acts\nBased on the tagging of the current text, we will recognize act beginnings by the sequence |A at the beginning of a line.\n\n\nTable 3: Data after act has been assigned.\n\n\nlinenumber\n\n\ntext\n\n\nact\n\n\n65\n\n\nAnd when he says he is, say that he dreams,\n\n\n1\n\n\n66\n\n\nFor he is nothing but a mighty lord.\n\n\n1\n\n\n67\n\n\nThis do, and do it kindly, gentle sirs;\n\n\n1\n\n\n68\n\n\nIt will be pastime passing excellent,\n\n\n1\n\n\n69\n\n\nIf it be husbanded with modesty. verseend\n\n\n1\n\n\n70\n\n\nHUNTSMAN1 versestart My lord, I warrant you we will play our part\n\n\n1\n\n\n71\n\n\nAs he shall think by our true diligence\n\n\n1\n\n\n72\n\n\nHe is no less than what we say he is. verseend\n\n\n1\n\n\n73\n\n\n<LORD> versestart Take him up gently and to bed with him,\n\n\n1\n\n\n74\n\n\nAnd each one to his office when he wakes.\n\n\n1\n\n\n75\n\n\nSirrah, go see what trumpet ’tis that sounds.\n\n\n1\n\n\nTokenize\nWe have covered our bases now and can use the default setting of the unnest_tokens() function with regard to removal of punctuation, but not with regard to lower-casing across the board.\n\n\nTable 4: Data after tokenization, with option to_lower = FALSE.\n\n\nlinenumber\n\n\nact\n\n\nword\n\n\n9\n\n\n1\n\n\na\n\n\n9\n\n\n1\n\n\ndenier\n\n\n9\n\n\n1\n\n\nGo\n\n\n9\n\n\n1\n\n\nby\n\n\n9\n\n\n1\n\n\nSaint\n\n\n9\n\n\n1\n\n\nJeronimy\n\n\n9\n\n\n1\n\n\ngo\n\n\n10\n\n\n1\n\n\nto\n\n\n10\n\n\n1\n\n\nthy\n\n\n10\n\n\n1\n\n\ncold\n\n\n10\n\n\n1\n\n\nbed\n\n\nWe can now determine that the play has 23 223 words, as that is the number of rows in the text object after tokenization.\nMark each row for current speaker\nWe’re adding a new column and marking for each word who the speaker is.\n\n\n\n\n\nTable 5: Data after speaker has been assigned.\n\n\nlinenumber\n\n\nact\n\n\nword\n\n\nspeaker\n\n\n9\n\n\n1\n\n\na\n\n\nSLY\n\n\n9\n\n\n1\n\n\ndenier\n\n\nSLY\n\n\n9\n\n\n1\n\n\nGo\n\n\nSLY\n\n\n9\n\n\n1\n\n\nby\n\n\nSLY\n\n\n9\n\n\n1\n\n\nSaint\n\n\nSLY\n\n\n9\n\n\n1\n\n\nJeronimy\n\n\nSLY\n\n\n9\n\n\n1\n\n\ngo\n\n\nSLY\n\n\n10\n\n\n1\n\n\nto\n\n\nSLY\n\n\n10\n\n\n1\n\n\nthy\n\n\nSLY\n\n\n10\n\n\n1\n\n\ncold\n\n\nSLY\n\n\n10\n\n\n1\n\n\nbed\n\n\nSLY\n\n\n10\n\n\n1\n\n\nand\n\n\nSLY\n\n\n10\n\n\n1\n\n\nwarm\n\n\nSLY\n\n\n10\n\n\n1\n\n\nthee\n\n\nSLY\n\n\n10\n\n\n1\n\n\nproseend\n\n\nSLY\n\n\n11\n\n\n1\n\n\nHOSTESS\n\n\nHOSTESS\n\n\n11\n\n\n1\n\n\nprosestart\n\n\nHOSTESS\n\n\n11\n\n\n1\n\n\nI\n\n\nHOSTESS\n\n\n11\n\n\n1\n\n\nknow\n\n\nHOSTESS\n\n\n11\n\n\n1\n\n\nmy\n\n\nHOSTESS\n\n\n11\n\n\n1\n\n\nremedy\n\n\nHOSTESS\n\n\nNow that the speaker tagging in a dedicated column is in place, we will also remove those rows that contain only a speech prefix.\n\n\n\nMark each row for current genre\n\n\n\n\n\nTable 6: Data after genre has been assigned.\n\n\nlinenumber\n\n\nact\n\n\nword\n\n\nspeaker\n\n\ngenre\n\n\n10\n\n\n1\n\n\nto\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\nthy\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\ncold\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\nbed\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\nand\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\nwarm\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\nthee\n\n\nSLY\n\n\nprose\n\n\n10\n\n\n1\n\n\nproseend\n\n\nSLY\n\n\nprose\n\n\n11\n\n\n1\n\n\nprosestart\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nknow\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nmy\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nremedy\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nmust\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\ngo\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nfetch\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nthe\n\n\nHOSTESS\n\n\nprose\n\n\n12\n\n\n1\n\n\nthirdborough\n\n\nHOSTESS\n\n\nprose\n\n\n12\n\n\n1\n\n\nproseend\n\n\nHOSTESS\n\n\nprose\n\n\n13\n\n\n1\n\n\nprosestart\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nThird\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nor\n\n\nSLY\n\n\nprose\n\n\nNow that genres are tagged as well, we will also remove those rows that contain only a (lexical) genre tag.\n\n\n\nThe final file\nHere is a last view of the data, this time a bit longer.\n\n\nTable 7: Data after processing.\n\n\nlinenumber\n\n\nact\n\n\nword\n\n\nspeaker\n\n\ngenre\n\n\n11\n\n\n1\n\n\nmy\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nremedy\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nmust\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\ngo\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nfetch\n\n\nHOSTESS\n\n\nprose\n\n\n11\n\n\n1\n\n\nthe\n\n\nHOSTESS\n\n\nprose\n\n\n12\n\n\n1\n\n\nthirdborough\n\n\nHOSTESS\n\n\nprose\n\n\n13\n\n\n1\n\n\nThird\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nor\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nfourth\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nor\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nfift\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nborough\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nI’ll\n\n\nSLY\n\n\nprose\n\n\n13\n\n\n1\n\n\nanswer\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nhim\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nby\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nlaw\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nI’ll\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nnot\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nbudge\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nan\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\ninch\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nboy\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nlet\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\nhim\n\n\nSLY\n\n\nprose\n\n\n14\n\n\n1\n\n\ncome\n\n\nSLY\n\n\nprose\n\n\n15\n\n\n1\n\n\nand\n\n\nSLY\n\n\nprose\n\n\n15\n\n\n1\n\n\nkindly\n\n\nSLY\n\n\nprose\n\n\n16\n\n\n1\n\n\nHuntsman\n\n\nLORD\n\n\nverse\n\n\n16\n\n\n1\n\n\ncharge\n\n\nLORD\n\n\nverse\n\n\n16\n\n\n1\n\n\nthee\n\n\nLORD\n\n\nverse\n\n\n16\n\n\n1\n\n\ntender\n\n\nLORD\n\n\nverse\n\n\n16\n\n\n1\n\n\nwell\n\n\nLORD\n\n\nverse\n\n\n16\n\n\n1\n\n\nmy\n\n\nLORD\n\n\nverse\n\n\n16\n\n\n1\n\n\nhounds\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\nBrach\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\nMerriman\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\nthe\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\npoor\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\ncur\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\nis\n\n\nLORD\n\n\nverse\n\n\n17\n\n\n1\n\n\nemboss’d\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\nAnd\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\ncouple\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\nClowder\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\nwith\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\nthe\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\ndeep\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\nmouth’d\n\n\nLORD\n\n\nverse\n\n\n18\n\n\n1\n\n\nbrach\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nSaw’st\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nthou\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nnot\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nboy\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nhow\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nSilver\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nmade\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\nit\n\n\nLORD\n\n\nverse\n\n\n19\n\n\n1\n\n\ngood\n\n\nLORD\n\n\nverse\n\n\n20\n\n\n1\n\n\nAt\n\n\nLORD\n\n\nverse\n\n\n\n\n\n\n\n\n",
    "preview": "posts/dataprep/shrew_markup.png",
    "last_modified": "2020-10-21T09:45:54-04:00",
    "input_file": {}
  },
  {
    "path": "posts/some-numbers/",
    "title": "2 - Some Numbers",
    "description": "Descriptive statistics about the text's dimensions by genre, speaker, and act.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-10-17",
    "categories": [],
    "contents": "\n\nContents\nDescriptive Statistics\nResearch Questions\nText Volume by Genre, Character, ActCharacter\nGenre\nGenre and Character\n\nGenre and Character by Act\n\nDescriptive Statistics\nEverything we’ve done to the text so far, including the hand coding, is called text mining. By conducting some counts and visualizations here of the distributions in our variables of interest, we are moving into what data scientists call descriptive statistics. (And the next level of statistical complexity would be called predictive statistics, or modeling, or machine learning, or AI.)\n\nOur “variables of interest” are, for now: genre, speaker, and act.\nMany digital text analysis projects are best served by careful descriptive statistics, and this is one of them.\n\n\n\nResearch Questions\nReceived from Doug Bruster via email.\nHow many words of verse in this play?\nHow many words of prose?\nHow many of each does each character speak?\nWhat is the overall sentiment of the verse speeches?\nWhat is the overall sentiment of the prose speeches?\nIs there a discrepancy in the sentiment of the verse a certain character speaks as opposed to the sentiment of the prose he or she speaks (that is, a wider or narrower gap than the average difference of the two media)?\nAre verse and prose made up of different kinds of words (for example, are the words in one medium longer in terms of character count than the other)?\nAre the lexicons of verse and prose ordered differently? (That is, do the most frequent words differ from one to the other?)\nText Volume by Genre, Character, Act\n\n\n\nCharacter\nFirst, let’s see which character has how many words.\n\n\n\nFigure 1: Number of words per character.\n\n\n\nGenre\n\n\n\nFigure 2: Number of words per character.\n\n\n\nGenre and Character\n\n\n\nFigure 3: Number of words per character and genre.\n\n\n\nBelow is the same chart but showing only characters who use both prose and verse.\n\n\n\nGenre and Character by Act\nLet us focus on just the characters who use both genres. They are:\n\n [1] \"BAPTISTA\"  \"BIANCA\"    \"BIONDELLO\" \"GREMIO\"    \"GRUMIO\"   \n [6] \"HORTENSIO\" \"KATHARINA\" \"LORD\"      \"LUCENTIO\"  \"PEDANT\"   \n[11] \"PETRUCHIO\" \"SLY\"       \"TAILOR\"    \"TRANIO\"    \"VINCENTIO\"\n\nLet’s see how they mix across the five acts.\n\n\n\nFigure 4: Speech volume across acts by genre.\n\n\n\n\n\n\n",
    "preview": "posts/some-numbers/numbers.jpg",
    "last_modified": "2020-10-21T09:46:36-04:00",
    "input_file": {}
  },
  {
    "path": "posts/sentiment-analysis/",
    "title": "3 - Sentiment Analysis",
    "description": "Application of two-way sentiment analysis based on the Bing Liu lexicon.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-10-16",
    "categories": [],
    "contents": "\n\nContents\nTagging the data\nSentiment by Genre and ActBy Act\nBy Act and Genre\n\nSentiment by Character\nSentiment by Character and Genre\n\n\n\n\nFigure 1: Sentiments!\n\n\n\nTagging the data\nWe continue working with the previous version of the data – with one word per row, with act, speaker, and genre marked – and now add: (a) stopword removal and (b) neg./pos. sentiment tagging.\nWe must concede that, although we have a version of the text here that is orthographically modernized, it’s still written in an old form of English with a number of words that are not included in a modern-day sentiment lexicon such as Bing Liu’s.\nWe can output a version of the text that has had the stopwords removed, and then shows us the words that were not mapped to a term in the sentiment dictionary (in other words, they were found neither in the stopwords list nor in the sentiment lists).\n\nExtracting just the first 25 entries from the “words” column.\n\n [1] \"richard\"      \"conqueror\"    \"paucas\"       \"pallabris\"   \n [5] \"world\"        \"slide\"        \"sessa\"        \"pay\"         \n [9] \"glasses\"      \"burst\"        \"denier\"       \"jeronimy\"    \n[13] \"thy\"          \"bed\"          \"thee\"         \"fetch\"       \n[17] \"thirdborough\" \"fourth\"       \"fift\"         \"borough\"     \n[21] \"answer\"       \"law\"          \"budge\"        \"inch\"        \n[25] \"boy\"          \"huntsman\"    \n\nIt’s not too terrible. Well – thee, thy etc. should have been removed as stopwords, but it’s alright. We can apply the method and trust it will tell us something informative Here, then, is the top of the list of words that were sentiment-tagged.\n\nI wonder if there is a stopword list or sentiment dictionary for Renaissance/Early Modern English. It seems like something that a digital scholar might have created by now.\n\n\nTable 1: Top of the sentiment-tagged text object.\n\n\nspeaker\n\n\nword\n\n\nsentiment\n\n\nlinenumber\n\n\nact\n\n\ngenre\n\n\nSLY\n\n\nfaith\n\n\npositive\n\n\n1\n\n\n1\n\n\nprose\n\n\nHOSTESS\n\n\nrogue\n\n\nnegative\n\n\n2\n\n\n1\n\n\nprose\n\n\nSLY\n\n\nsaint\n\n\npositive\n\n\n9\n\n\n1\n\n\nprose\n\n\nSLY\n\n\ncold\n\n\nnegative\n\n\n10\n\n\n1\n\n\nprose\n\n\nSLY\n\n\nwarm\n\n\npositive\n\n\n10\n\n\n1\n\n\nprose\n\n\nHOSTESS\n\n\nremedy\n\n\npositive\n\n\n11\n\n\n1\n\n\nprose\n\n\nSLY\n\n\nkindly\n\n\npositive\n\n\n15\n\n\n1\n\n\nprose\n\n\nLORD\n\n\ntender\n\n\npositive\n\n\n16\n\n\n1\n\n\nverse\n\n\nLORD\n\n\npoor\n\n\nnegative\n\n\n17\n\n\n1\n\n\nverse\n\n\nLORD\n\n\nhedge\n\n\nnegative\n\n\n20\n\n\n1\n\n\nverse\n\n\nLORD\n\n\nfault\n\n\nnegative\n\n\n20\n\n\n1\n\n\nverse\n\n\nLORD\n\n\nlose\n\n\nnegative\n\n\n21\n\n\n1\n\n\nverse\n\n\nSentiment by Genre and Act\nBy Act\nFirst, an analysis that foregrounds textual structure more than character. The data is aggregated accordingly…\n\n\nTable 2: Sentiment scores per act.\n\n\nact\n\n\nsentiment\n\n\nn\n\n\ntotal_tagged\n\n\nprop\n\n\n1\n\n\nnegative\n\n\n194\n\n\n416\n\n\n0.466\n\n\n1\n\n\npositive\n\n\n222\n\n\n416\n\n\n0.534\n\n\n2\n\n\nnegative\n\n\n108\n\n\n214\n\n\n0.505\n\n\n2\n\n\npositive\n\n\n106\n\n\n214\n\n\n0.495\n\n\n3\n\n\nnegative\n\n\n90\n\n\n159\n\n\n0.566\n\n\n3\n\n\npositive\n\n\n69\n\n\n159\n\n\n0.434\n\n\n…and then plotted.\n\n\n\nFigure 2: Sentiment per act.\n\n\n\nBy Act and Genre\nFirst the data is converted…\n\n\nTable 3: Sentiment scores per act and genre.\n\n\nact\n\n\ngenre\n\n\nsentiment\n\n\nn\n\n\ntotal_tagged\n\n\nprop\n\n\n1\n\n\nprose\n\n\nnegative\n\n\n36\n\n\n71\n\n\n0.507\n\n\n1\n\n\nprose\n\n\npositive\n\n\n35\n\n\n71\n\n\n0.493\n\n\n1\n\n\nverse\n\n\nnegative\n\n\n158\n\n\n345\n\n\n0.458\n\n\n1\n\n\nverse\n\n\npositive\n\n\n187\n\n\n345\n\n\n0.542\n\n\n2\n\n\nprose\n\n\nnegative\n\n\n4\n\n\n10\n\n\n0.400\n\n\n2\n\n\nprose\n\n\npositive\n\n\n6\n\n\n10\n\n\n0.600\n\n\n2\n\n\nverse\n\n\nnegative\n\n\n104\n\n\n204\n\n\n0.510\n\n\n2\n\n\nverse\n\n\npositive\n\n\n100\n\n\n204\n\n\n0.490\n\n\n…and then plotted.\n\n\n\nFigure 3: Sentiment per act and genre. Token counts are high enough for each act so the Ns aren’t reported (but cp. other plots below).\n\n\n\n\nKind of a nice trend here! A general pattern that only Act 2 departs from.\nSentiment by Character\nWe can produce a value for the proportion of neg. and pos. terms out of the total number of terms tagged for each character.\n\n\nTable 4: Sentiment scores per character\n\n\nspeaker\n\n\nsentiment\n\n\nn\n\n\ntotal_tagged\n\n\nprop\n\n\nBAPTISTA\n\n\nnegative\n\n\n41\n\n\n79\n\n\n0.519\n\n\nBAPTISTA\n\n\npositive\n\n\n38\n\n\n79\n\n\n0.481\n\n\nBIANCA\n\n\nnegative\n\n\n19\n\n\n36\n\n\n0.528\n\n\nBIANCA\n\n\npositive\n\n\n17\n\n\n36\n\n\n0.472\n\n\nBIONDELLO\n\n\nnegative\n\n\n21\n\n\n43\n\n\n0.488\n\n\nBIONDELLO\n\n\npositive\n\n\n22\n\n\n43\n\n\n0.512\n\n\nLet’s visualize these. Using proportions (or percentages) means that all the characters are displayed on the same scale, even though some of them have very, very few words. When a character has only a couple of words scored, there’s a bit of significance issue. Therefore I’ll include the number of words scored per character in the visualization: it will be proportional to the width of the bars for each character.\n\n\n\nFigure 4: Proportion of sentiment scores per character. Label in white shows number of items scored per character as an indicator of reliability\n\n\n\n\nThe numbers of items tagged in each category for this plot are great enough to let this analysis be fairly robust.\nSentiment by Character and Genre\nFor this analysis, we break down the aggregate sentiment scores by character and genre. That is to say, we’ll end up with a dataset that contains (up to) four rows per character: it splits two ways for genre and then two ways for sentiment.\n\n\nTable 5: Sentiment scores aggregated by character and genre.\n\n\nspeaker\n\n\ngenre\n\n\nsentiment\n\n\nn\n\n\ntotal_tagged\n\n\nprop\n\n\nBAPTISTA\n\n\nprose\n\n\nnegative\n\n\n5\n\n\n7\n\n\n0.714\n\n\nBAPTISTA\n\n\nprose\n\n\npositive\n\n\n2\n\n\n7\n\n\n0.286\n\n\nBAPTISTA\n\n\nverse\n\n\nnegative\n\n\n36\n\n\n72\n\n\n0.500\n\n\nBAPTISTA\n\n\nverse\n\n\npositive\n\n\n36\n\n\n72\n\n\n0.500\n\n\nBIANCA\n\n\nprose\n\n\nnegative\n\n\n1\n\n\n2\n\n\n0.500\n\n\nBIANCA\n\n\nprose\n\n\npositive\n\n\n1\n\n\n2\n\n\n0.500\n\n\nBIANCA\n\n\nverse\n\n\nnegative\n\n\n18\n\n\n34\n\n\n0.529\n\n\nBIANCA\n\n\nverse\n\n\npositive\n\n\n16\n\n\n34\n\n\n0.471\n\n\nBIONDELLO\n\n\nprose\n\n\nnegative\n\n\n18\n\n\n35\n\n\n0.514\n\n\nBIONDELLO\n\n\nprose\n\n\npositive\n\n\n17\n\n\n35\n\n\n0.486\n\n\nBIONDELLO\n\n\nverse\n\n\nnegative\n\n\n3\n\n\n8\n\n\n0.375\n\n\nBIONDELLO\n\n\nverse\n\n\npositive\n\n\n5\n\n\n8\n\n\n0.625\n\n\nLet us visualize these new numbers. A caveat: when there are too few items in a category (anything under about 4 has no statistical meaning), results must be taken with more than a grain of salt. Findings for the characters with more words can be trusted, however.\n\n\n\nFigure 5: Crossing sentiment scores several ways.\n\n\n\n\n\n\n",
    "preview": "posts/sentiment-analysis/sentiments.jpg",
    "last_modified": "2020-10-21T09:46:51-04:00",
    "input_file": {}
  },
  {
    "path": "posts/part-of-speech-tagging/",
    "title": "4 - Part-of-Speech Distribution",
    "description": "Analysis of POS frequencies by character and genre.",
    "author": [
      {
        "name": "Lars Hinrichs",
        "url": "https://larshinrichs.site"
      }
    ],
    "date": "2020-10-15",
    "categories": [],
    "contents": "\n\nContents\nData selection\nPrimer: why POS frequencies are interesting\nVerbal style\nNominal style\nNote on significance\n\nPOS frequencies in the data\nDefinition of POS indices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData selection\nWe’ll extract the 14 speakers with the most words from the data. They are:\n\n\nspeaker\n\n\nn\n\n\nPETRUCHIO\n\n\n4557\n\n\nTRANIO\n\n\n2361\n\n\nKATHARINA\n\n\n1832\n\n\nHORTENSIO\n\n\n1773\n\n\nGRUMIO\n\n\n1657\n\n\nLUCENTIO\n\n\n1443\n\n\nBAPTISTA\n\n\n1271\n\n\nGREMIO\n\n\n1187\n\n\nLORD\n\n\n1080\n\n\nBIONDELLO\n\n\n813\n\n\nSLY\n\n\n539\n\n\nBIANCA\n\n\n518\n\n\nPEDANT\n\n\n393\n\n\nVINCENTIO\n\n\n341\n\n\n\n\n\nPrimer: why POS frequencies are interesting\nVerbal style\nHigher frequencies of verbs (and attendant parts of speech) indicate dynamic communication, social intelligence, action-focused modes of thought, relational psychology (i.e. relating to other characters).\nNominal style\nHigher frequencies of nouns (and attendant parts of speech) indicate conceptual thinking, declarative intelligence, epistemological interest, fact-oriented modes of thought, investigative/academic psychology.\nNote on significance\nBecause of the high frequencies of tokens in the analysis of POS-tags, even small differences in proportions can be considered significant.\nPOS frequencies in the data\nThe data has been part-of-speech tagged in the background. The tagger we’re using assigns a set of 36 different tags.\n\n [1] \"ADD\"  \"CC\"   \"CD\"   \"DT\"   \"EX\"   \"FW\"   \"IN\"   \"JJ\"   \"JJR\" \n[10] \"JJS\"  \"MD\"   \"NN\"   \"NNP\"  \"NNPS\" \"NNS\"  \"PDT\"  \"POS\"  \"PRP\" \n[19] \"PRP$\" \"RB\"   \"RBR\"  \"RBS\"  \"RP\"   \"TO\"   \"UH\"   \"VB\"   \"VBD\" \n[28] \"VBG\"  \"VBN\"  \"VBP\"  \"VBZ\"  \"WDT\"  \"WP\"   \"WP$\"  \"WRB\"  \"XX\"  \n\nThankfully, it also has a set of meta-categories, so I won’t need to define any myself They are:\n\n [1] \"ADJ\"   \"ADP\"   \"ADV\"   \"AUX\"   \"CCONJ\" \"DET\"   \"INTJ\"  \"NOUN\" \n [9] \"NUM\"   \"PART\"  \"PRON\"  \"PROPN\" \"SCONJ\" \"VERB\"  \"X\"    \n\nThere are 15 of them.\nDefinition of POS indices\nWe are interested in “verbal” vs. “nominal” style. These can be measured in the frequencies of the “VERB” and the “NOUN” tags, respectively, but I want to also include the attendant POS groups that co-vary with those two:\nverbs co-vary with auxiliary verbs and adverbs; and\nnouns co-vary with determiners, adjectives, and prepositions.\nSo I’ll form two index groups:\n\n\nverb_index <- c(\"VERB\", \"AUX\", \"ADV\")\nnoun_index <- c(\"NOUN\", \"PROPN\", \"ADP\", \"DET\", \"ADJ\")\n\n\n\nHere are the relationships between verbal and nominal indices by the top-14 characters.\n\n\n\nFigure 1: Tokens in the index groups for nouns, verbs, and “other”.\n\n\n\nThis graph does not communicate very clearly what we actually want to know, which is the ratio between frequency of tags in the noun group and those in the verb group. So let’s eliminate “other” and focus only on the verb and noun tags.\n\n\n\nFigure 2: Frequency of tags in index groups as ratio between n and v.\n\n\n\nFinally, we can break up the noun:verb ratio for each speaker by genre.\n\n\n\nFigure 3: Frequency of tags in n/v index groups, by genre.\n\n\n\n\n\n\n",
    "preview": "posts/part-of-speech-tagging/blocks.png",
    "last_modified": "2020-10-29T16:11:00-04:00",
    "input_file": "part-of-speech-tagging.utf8.md"
  }
]
